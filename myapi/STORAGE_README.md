# 분석 결과 저장/로드 시스템 + 배치 처리 최적화

## 개요
이 시스템은 분석 결과와 시각화 데이터를 자동으로 저장하고, 필요할 때 다시 로드할 수 있게 해주는 기능입니다. 한 번 생성한 분석 결과를 재사용하여 시간을 절약할 수 있습니다. 또한 LLM 태깅을 위한 배치 처리 시스템을 통해 성능을 크게 향상시킬 수 있습니다.

## 주요 기능

### 1. 자동 저장
- **시각화 생성**: 레이더 차트, 히트맵, 정렬 차트 생성 시 자동 저장
- **구조화된 분석**: 의미 태깅 및 분석 결과 생성 시 자동 저장
- **메타데이터**: 분석 정보, 생성 시간, 데이터 해시 등 포함

### 2. 저장된 분석 관리
- **목록 조회**: 저장된 모든 분석 결과를 시간순으로 정렬하여 표시
- **상세 정보**: 각 분석의 포함된 시각화 타입, 실험명, 질문 번호 등 표시
- **빠른 로드**: 클릭 한 번으로 저장된 분석 결과를 즉시 로드

### 3. 데이터 영속성
- **파일 기반 저장**: pickle 형식으로 분석 데이터 저장
- **메타데이터**: JSON 형식으로 분석 정보 저장
- **해시 기반**: 데이터 무결성 검증을 위한 MD5 해시 생성

### 4. 배치 처리 최적화
- **LLM 태깅 배치화**: 여러 응답을 한 번에 처리하여 API 호출 최소화
- **성능 향상**: 개별 처리 대비 3-5배 빠른 처리 속도
- **메모리 최적화**: 가비지 컬렉션 및 메모리 정리 자동화
- **재시도 로직**: API 실패 시 자동 재시도 및 fallback 처리

## API 엔드포인트

### 저장된 분석 목록 조회
```
GET /visualization/saved-analyses
```
저장된 모든 분석 결과의 메타데이터 목록을 반환합니다.

### 저장된 분석 상세 조회
```
GET /visualization/saved-analyses/{analysis_id}
```
특정 분석 ID의 전체 데이터와 메타데이터를 반환합니다.

### 저장된 분석 삭제
```
DELETE /visualization/saved-analyses/{analysis_id}
```
특정 분석 결과를 삭제합니다.

### 수동 분석 저장
```
POST /visualization/save-analysis
```
사용자가 직접 분석 결과를 저장할 수 있습니다.

### 분석 정보 조회
```
GET /visualization/analysis-info/{analysis_id}
```
분석의 메타데이터만 조회합니다.

## 프론트엔드 기능

### 저장된 분석 목록
- 실험명, 질문 번호, 분석 타입, 생성 시간 표시
- 포함된 시각화 타입 (레이더, 히트맵, 정렬, 구조화) 표시
- 로드 및 삭제 버튼 제공

### 빠른 로드
- 분석 ID 입력으로 직접 로드
- 저장된 목록에서 클릭으로 로드
- 로드된 결과를 즉시 시각화

### 관리 기능
- 개별 분석 결과 삭제
- 전체 저장된 분석 결과 삭제
- 목록 새로고침

## 배치 처리 설정

### 설정 파일
`batch_config.py` 파일에서 배치 처리 관련 설정을 관리할 수 있습니다:

```python
# OpenAI API 설정
OPENAI_CONFIG = {
    "model": "gpt-3.5-turbo",
    "temperature": 0.1,
    "max_tokens": 1000,
    "timeout": 30,
}

# 배치 처리 설정
BATCH_CONFIG = {
    "default_batch_size": 10,      # 기본 배치 크기
    "max_batch_size": 20,          # 최대 배치 크기
    "min_batch_size": 5,           # 최소 배치 크기
    "api_call_delay": 0.1,         # API 호출 간격 (초)
    "max_retries": 3,              # 최대 재시도 횟수
    "retry_delay": 1.0,            # 재시도 간격 (초)
}
```

### 성능 최적화
- **응답 수 5개 미만**: 개별 처리 (배치 오버헤드 방지)
- **응답 수 5-10개**: 기본 배치 크기 사용
- **응답 수 10개 이상**: 최적화된 배치 크기로 처리
- **대용량 데이터**: 메모리 사용량을 고려한 배치 크기 조정

### 모니터링 및 로깅
- 배치 진행률 실시간 표시
- 성능 메트릭 (처리 시간, 응답당 평균 시간)
- 메모리 사용량 모니터링
- 오류 발생 시 상세 로깅

## 저장 구조

```
saved_analyses/
├── {experiment_name}_Q{question_index}_{analysis_type}_{hash}.pkl
└── {experiment_name}_Q{question_index}_{analysis_type}_{hash}_metadata.json
```

### 파일 형식
- **.pkl**: Python pickle 형식으로 분석 데이터 저장
- **.json**: 메타데이터 및 요약 정보 저장

### 메타데이터 구조
```json
{
  "analysis_id": "실험명_Q0_all_abc12345",
  "experiment_name": "실험명",
  "question_index": 0,
  "analysis_type": "all",
  "data_hash": "abc12345",
  "created_at": "2024-01-01T12:00:00",
  "summary": {
    "has_radar": true,
    "has_heatmap": true,
    "has_sorting": true,
    "has_structured": false
  }
}
```

## 사용 방법

### 1. 자동 저장
분석을 실행하면 자동으로 저장됩니다:
- 시각화 생성 시
- 구조화된 분석 생성 시
- 분석 ID가 응답에 포함됨

### 2. 저장된 분석 로드
1. 저장된 분석 목록에서 "📥 로드" 버튼 클릭
2. 또는 분석 ID를 직접 입력하여 로드
3. 로드된 결과가 즉시 표시됨

### 3. 분석 결과 관리
- 개별 삭제: 각 분석의 "🗑️ 삭제" 버튼
- 전체 삭제: "🗑️ 전체 삭제" 버튼
- 목록 새로고침: "🔄 목록 새로고침" 버튼

## 장점

1. **시간 절약**: 한 번 생성한 분석 결과를 재사용
2. **데이터 보존**: 분석 결과와 시각화 데이터 영구 보존
3. **빠른 접근**: 저장된 결과를 즉시 로드하여 표시
4. **효율적 관리**: 분석 결과의 체계적 관리 및 정리
5. **무결성**: 해시 기반 데이터 무결성 검증

## 주의사항

- 저장된 데이터는 서버 재시작 후에도 유지됩니다
- 대용량 데이터의 경우 저장/로드 시간이 걸릴 수 있습니다
- 전체 삭제는 되돌릴 수 없으니 주의하세요
- 저장 디렉토리(`saved_analyses`)의 권한을 확인하세요

## 문제 해결

### 저장 실패
- 디렉토리 권한 확인
- 디스크 공간 확인
- 파일명에 사용할 수 없는 문자 제거

### 로드 실패
- 분석 ID 확인
- 파일 존재 여부 확인
- 서버 로그 확인

### 메모리 부족
- 대용량 분석 결과의 경우 메모리 사용량 모니터링
- 필요시 분석 결과를 더 작은 단위로 분할

## 배치 처리 테스트

### 테스트 스크립트 실행
```bash
# 배치 설정 테스트
python batch_config.py

# 배치 처리 기능 테스트
python test_batch_processing.py

# 성능 비교 테스트
python performance_comparison.py
```

### 테스트 결과 확인
- 배치 설정 파일 로드 상태
- LLM Tagger 초기화 상태
- 배치 처리 로직 동작 확인
- 성능 향상 수치 측정

### 성능 최적화 팁
- 응답 수가 많을수록 배치 처리 효과 증가
- API Rate Limit을 고려한 적절한 간격 설정
- 메모리 사용량 모니터링 및 정리
- 오류 발생 시 자동 fallback 활용
