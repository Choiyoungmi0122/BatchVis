# BatchPro - 가상환자 페르소나 생성 및 분석 시스템

## 개요
BatchPro는 OpenAI Batch API를 활용하여 **25개 TCI(Temperament and Character Inventory) 성향 조합**을 가진 가상환자 페르소나를 생성하고, 이들의 응답을 분석하는 시스템입니다.

## 주요 기능

### 1. 가상환자 페르소나 생성
- **TCI 기반 페르소나**: **25개 선택된 기질(Temperament)과 성격(Character) 조합**으로 페르소나 생성
- **Batch API 활용**: OpenAI Batch API를 통한 대량 처리로 비용 효율성 증대
- **다양한 질문에 대한 응답**: 11가지 표준화된 질문에 대한 페르소나별 답변 생성
- **최신 모델 사용**: GPT-4-turbo-preview 모델로 고품질 응답 생성

### 2. 페르소나 필터링 시스템
- **TCI 성향별 필터링**: 기질과 성격의 세부 특성(상/중/하)에 따른 필터링
- **실시간 필터링**: 드롭다운 방식의 직관적인 UI로 원하는 페르소나 빠른 검색
- **필터링 결과 요약**: 전체/필터링된 페르소나 수 실시간 표시

### 3. **페르소나 응답 유사도 분석** 🆕
- **Sentence Transformers 기반**: 다국어 지원 BERT 모델을 활용한 의미적 유사도 분석
- **다양한 분석 방법**:
  - **유사도 행렬**: 모든 페르소나 응답 간 코사인 유사도 계산
  - **클러스터링**: K-means, DBSCAN을 통한 응답 그룹화
  - **차원 축소**: t-SNE, PCA를 통한 2D 시각화
- **통계 분석**: 유사도 분포, 최고/최저 유사 응답 쌍, 클러스터 통계
- **시각화**: 히트맵, 히스토그램, 산점도 등 다양한 차트 제공

### 4. **구조화된 분석** 🆕
- **자동 태깅 시스템**: LLM을 활용한 응답의 자동 분류 및 태깅
- **6가지 분석 축**: 감정 방향, 감정 강도, 행동 성향, 관계 지향성, 지원 요청 여부, 표현 스타일
- **Batch 처리**: 대량 응답 처리 시 3-5배 속도 향상
- **자동 저장/로드**: 분석 결과 자동 저장 및 재사용

## 기술 스택

### Backend
- **FastAPI**: 고성능 Python 웹 프레임워크
- **OpenAI API**: **GPT-4-turbo-preview** 모델을 활용한 가상환자 응답 생성
- **Sentence Transformers**: 다국어 텍스트 임베딩 및 유사도 계산
- **scikit-learn**: 클러스터링 및 차원 축소 알고리즘
- **NumPy/Pandas**: 수치 계산 및 데이터 처리

### Frontend
- **HTML/CSS/JavaScript**: 반응형 웹 인터페이스
- **Chart.js**: 데이터 시각화
- **Plotly**: 인터랙티브 차트 및 그래프

## 설치 및 실행

### 1. 환경 설정
```bash
# Conda 환경 생성 및 활성화
conda create -n batchpro python=3.9
conda activate batchpro
```

### 2. 의존성 설치
```bash
pip install -r requirements.txt
```

### 3. 환경 변수 설정
`.env` 파일을 생성하고 OpenAI API 키를 설정:
```
OPENAI_API_KEY=your_openai_api_key_here
```

### 4. 서버 실행
```bash
cd myapi
uvicorn main:app --reload
```

### 5. 프론트엔드 접속
브라우저에서 `http://localhost:8000` 접속

## 사용법

### 페르소나 생성
1. **실험 시작**: "실험 시작" 버튼 클릭하여 실험 번호 생성
2. **환자 정보 입력**: 이름, 나이, 성별, 주증상 입력 (예: "홍길동, 24세, 남성, 우울증")
3. **Batch API 실행**: "Batch API 실행" 버튼으로 **25개 페르소나 × 11개 질문** 처리
4. **결과 확인**: 생성된 응답들을 페르소나별로 확인

### 페르소나 필터링
1. **TCI 성향 선택**: 기질과 성격의 세부 특성에서 원하는 수준(상/중/하) 선택
2. **필터 적용**: "필터 적용" 버튼으로 선택된 조건에 맞는 페르소나만 표시
3. **필터 해제**: "필터 해제" 버튼으로 선택된 필터 제거
4. **초기화**: "초기화" 버튼으로 모든 필터 초기 상태로 복원

### **유사도 분석** 🆕
1. **분석 설정**: 분석 유형 선택 (전체/유사도 행렬/클러스터링/차원 축소)
2. **실험 파일 선택**: 분석할 실험 파일들을 체크박스로 선택
3. **분석 실행**: "분석 시작" 버튼으로 유사도 분석 실행
4. **결과 확인**:
   - **통계 보기**: 유사도 분포, 최고/최저 유사 응답 쌍, 클러스터 정보
   - **시각화**: 히트맵, 히스토그램, 클러스터링 결과, t-SNE/PCA 차트
   - **결과 내보내기**: JSON 형태로 분석 결과 다운로드

### **구조화된 분석** 🆕
1. **분석 설정**: 실험, 질문, 의미 축 선택
2. **분석 실행**: "분석 시작" 버튼으로 구조화된 분석 실행
3. **자동 처리**: LLM을 활용한 자동 태깅 및 분류
4. **결과 확인**: 6가지 축별 분석 결과 및 시각화

## API 엔드포인트

### 기본 기능
- `POST /start_experiment`: 실험 번호 생성
- `POST /process_qa_batch`: Batch API를 통한 가상환자 응답 생성 (**25개 조합**)
- `GET /list_experiments`: 저장된 실험 목록 조회
- `GET /get_experiment_input/{filename}`: 특정 실험 데이터 로드

### **유사도 분석** 🆕
- `POST /analyze_similarity`: 페르소나 응답 간 의미 유사도 분석
- `POST /generate_similarity_visualizations`: 유사도 분석 결과 시각화
- `POST /get_similarity_statistics`: 유사도 분석 통계 정보
- `POST /find_similar_responses`: 특정 응답과 유사한 응답들 검색

### **구조화된 분석** 🆕
- `POST /visualization/structured-analysis`: 구조화된 분석 생성
- `GET /visualization/saved-analyses`: 저장된 분석 목록 조회
- `GET /visualization/saved-analyses/{analysis_id}`: 특정 분석 결과 로드



### **유사도 분석 결과** 🆕
```json
{
  "total_responses": 275,
  "similarity_matrix": [[1.0, 0.85, ...], ...],
  "responses_info": [...],
  "clustering": {
    "kmeans_labels": [0, 1, 2, ...],
    "dbscan_labels": [0, 1, -1, ...]
  },
  "dimensionality_reduction": {
    "tsne": [[x1, y1], [x2, y2], ...],
    "pca": [[x1, y1], [x2, y2], ...]
  }
}
```

### **구조화된 분석 결과** 🆕
```json
{
  "analysis_id": "experiment_20250817_Q0",
  "persona_responses": [
    {
      "persona": "고립되고 겁이 많은, 미성숙한",
      "text": "응답 텍스트...",
      "tags": {
        "감정_방향": "부정",
        "감정_강도": "강함",
        "행동_성향": "수동적",
        "관계_지향성": "자기중심",
        "지원_요청_여부": "암시적 요청",
        "표현_스타일": "위로형"
      }
    }
  ]
}
```

## 성능 최적화

### **Batch API 처리 시간**
- **기존 36개 조합**: 약 45분
- **현재 25개 조합**: 약 **27-28분** (약 38% 시간 단축)
- **질문당 처리**: 11개 질문 × 25개 조합 = 275개 응답

### **구조화된 분석 성능**
- **개별 처리**: 10개 응답당 ~30초
- **Batch 처리**: 10개 응답당 **~8초** (3.8배 속도 향상)
- **자동 저장/로드**: 기존 분석 시 즉시 결과 확인

## 활용 사례

### 연구 및 교육
- **심리학 연구**: TCI 성향별 응답 패턴 분석
- **의료 교육**: 다양한 성향의 환자와의 상담 시뮬레이션
- **AI 연구**: 페르소나 기반 대화 시스템 개발

### **데이터 분석** 🆕
- **응답 유사성 분석**: 성향별 응답 패턴의 유사성 및 차이점 파악
- **클러스터링**: 유사한 응답 패턴을 보이는 페르소나 그룹 식별
- **차원 축소**: 고차원 응답 데이터의 2D 시각화를 통한 패턴 발견
- **구조화된 분석**: LLM 기반 자동 태깅으로 체계적인 응답 분류

## 주의사항

1. **API 키 보안**: OpenAI API 키를 안전하게 보관하고 공개 저장소에 업로드하지 않음
2. **데이터 처리 시간**: 25개 조합 처리 시 약 27-28분 소요
3. **메모리 사용량**: 유사도 분석 시 대용량 행렬 계산으로 인한 메모리 사용량 증가
4. **모델 다운로드**: Sentence Transformers 모델 첫 실행 시 다운로드 시간 필요
5. **Batch API 제한**: OpenAI Batch API 사용량 및 제한사항 확인

## 라이선스
이 프로젝트는 MIT 라이선스 하에 배포됩니다.

## 기여
버그 리포트, 기능 제안, 풀 리퀘스트를 환영합니다.

---

# 분석 결과 저장/로드 시스템

## 개요
이 시스템은 페르소나 응답 분석 결과를 자동으로 저장하고, 동일한 실험/질문에 대한 재분석 시 기존 결과를 자동으로 로드하여 분석 시간을 단축합니다.

## 주요 기능

### 1. 자동 저장 (Auto-Save)
- 분석 실행 시 모든 결과가 자동으로 저장됩니다
- 실험명과 질문 인덱스를 기반으로 고유 ID 생성
- 기존 분석이 있으면 자동으로 덮어쓰기

### 2. 자동 로드 (Auto-Load)
- 동일한 실험/질문 조합에 대해 기존 분석이 있으면 자동 로드
- 사용자는 별도의 로드 작업 없이 즉시 결과 확인 가능
- 분석 시간 대폭 단축 (기존: 30초~2분 → 개선: 즉시)

### 3. Batch 처리 (Batch Processing) 🚀
- **LLM 태깅 성능 대폭 향상**: 개별 처리 대비 **3-5배 빠른 속도**
- **Batch 크기**: 기본 10개 응답을 한 번에 처리
- **API 호출 최적화**: OpenAI API 호출 횟수 대폭 감소
- **Rate Limit 방지**: 적절한 간격으로 API 호출 조절
- **Fallback 지원**: Batch 실패 시 개별 처리로 자동 전환

#### Batch 처리 성능 비교
| 처리 방식 | 10개 응답 | 50개 응답 | 100개 응답 |
|-----------|-----------|-----------|------------|
| 개별 처리 | ~30초 | ~2.5분 | ~5분 |
| **Batch 처리** | **~8초** | **~40초** | **~1.5분** |
| **성능 향상** | **3.8배** | **3.8배** | **3.3배** |

### 4. 관리 기능
- 저장된 분석 목록 조회
- 특정 분석 결과 로드
- 불필요한 분석 결과 삭제
- 전체 분석 결과 정리

## API 엔드포인트

### 분석 생성/로드
- `POST /visualization/generate` - 시각화 생성 (자동 저장 포함)
- `POST /visualization/structured-analysis` - 구조화된 분석 생성 (자동 저장 포함)

### 저장된 분석 관리
- `GET /visualization/saved-analyses` - 저장된 분석 목록 조회
- `GET /visualization/saved-analyses/{analysis_id}` - 특정 분석 결과 로드
- `DELETE /visualization/saved-analyses/{analysis_id}` - 특정 분석 결과 삭제
- `POST /visualization/save-analysis` - 수동 저장
- `GET /visualization/analysis-info/{analysis_id}` - 분석 메타데이터 조회

## 프론트엔드 기능

### 자동 저장/로드
- 분석 시작 시 자동으로 기존 결과 확인
- 기존 결과가 있으면 즉시 표시
- 새로운 분석 시 자동 저장

### 저장된 분석 관리
- 저장된 분석 목록 표시
- 로드/삭제 기능
- 분석 정보 요약 표시

## 저장 구조

### 파일명 형식
```
{실험명}_Q{질문인덱스}_{해시값}.pkl
```

### 저장 데이터 구조
```json
{
  "analysis_id": "실험명_Q0",
  "experiment_name": "실험명",
  "question_index": 0,
  "data_hash": "a1b2c3d4",
  "created_at": "2024-01-01T12:00:00",
  "analysis_data": {
    "radar_chart": {...},
    "heatmap": {...},
    "sorting_chart": {...},
    "structured_analysis": {...}
  }
}
```

## 사용법

### 1. 기본 사용
1. 실험, 질문, 의미 축 선택
2. "분석 시작" 버튼 클릭
3. 시스템이 자동으로 기존 분석 확인
4. 기존 분석이 있으면 즉시 로드, 없으면 새로 생성 후 저장

### 2. Batch 처리 활용
- **자동 활성화**: 10개 이상의 응답이 있을 때 자동으로 Batch 처리
- **성능 모니터링**: 콘솔에서 Batch 처리 진행 상황 확인
- **에러 처리**: Batch 실패 시 자동으로 개별 처리로 전환

### 3. 저장된 분석 관리
- "저장된 분석 결과" 섹션에서 목록 확인
- 원하는 분석 결과 로드
- 불필요한 결과 삭제

## 장점

### 1. 시간 절약
- **기존**: 매번 30초~2분 대기
- **개선**: 기존 분석 시 즉시 결과 확인
- **Batch 처리**: 대량 응답 처리 시 3-5배 속도 향상

### 2. 리소스 효율성
- 중복 분석 방지
- API 호출 최적화
- 저장 공간 효율적 관리

### 3. 사용자 경험
- 즉시 결과 확인 가능
- 일관된 분석 결과
- 직관적인 관리 인터페이스

## 문제 해결

### 1. 저장 실패
- `saved_analyses` 폴더 권한 확인
- 디스크 공간 확인
- 파일명에 사용할 수 없는 문자 제거

### 2. 로드 실패
- 분석 ID 형식 확인
- 파일 존재 여부 확인
- 파일 손상 여부 확인

### 3. Batch 처리 실패
- OpenAI API 키 확인
- 네트워크 연결 상태 확인
- Rate Limit 상태 확인

## 기술적 세부사항

### Batch 처리 최적화
- **동적 배치 크기**: 응답 수에 따라 자동 조정
- **병렬 처리**: 여러 배치를 순차적으로 처리
- **에러 복구**: 개별 응답 실패 시 규칙 기반 분석으로 대체
- **메모리 효율성**: 대용량 데이터 처리 시 메모리 사용량 최적화

### 저장 최적화
- **해시 기반 중복 감지**: 동일 데이터 재저장 방지
- **압축 저장**: pickle을 통한 효율적인 직렬화
- **메타데이터 분리**: 빠른 검색을 위한 별도 JSON 파일

### 성능 모니터링
- **처리 시간 측정**: 각 단계별 소요 시간 로깅
- **배치 진행률**: 실시간 처리 상황 표시
- **에러 통계**: 실패율 및 원인 분석