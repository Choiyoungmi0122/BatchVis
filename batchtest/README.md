# batchtest - OpenAI Batch API 테스트

## 개요
이 폴더는 OpenAI Batch API의 테스트 및 검증을 위한 파일들을 포함합니다. Batch API를 통한 대량 처리의 성능과 정확성을 확인하고, 다양한 시나리오를 테스트합니다.

## 주요 파일

### 📝 **테스트 데이터**
- **`batchinput.jsonl`** - Batch API 입력 데이터
  - JSONL(JSON Lines) 형식
  - 각 라인마다 개별 요청 데이터
  - 페르소나별 질문 응답 생성 요청

### 🔬 **테스트 노트북**
- **`create_patients_answer (1).ipynb`** - Jupyter 노트북
  - 가상환자 응답 생성 테스트
  - 다양한 TCI 조합 테스트
  - 응답 품질 및 일관성 검증

## Batch API 테스트 목적

### **1. 성능 검증**
- **처리 속도**: 개별 API 호출 대비 Batch 처리 속도 측정
- **비용 효율성**: API 호출 횟수 감소로 인한 비용 절약 확인
- **동시성**: 대량 요청 처리 시 시스템 안정성 검증

### **2. 품질 검증**
- **응답 일관성**: 동일한 입력에 대한 응답 품질 확인
- **페르소나 특성**: TCI 조합별 응답의 차별화 정도 검증
- **에러 처리**: 다양한 에러 상황에서의 시스템 동작 확인

### **3. 확장성 테스트**
- **대용량 처리**: 275개 응답(25개 조합 × 11개 질문) 처리 능력
- **메모리 사용량**: 대량 데이터 처리 시 메모리 효율성
- **네트워크 안정성**: 장시간 Batch 작업의 안정성

## 테스트 시나리오

### **기본 시나리오**
1. **단일 질문 테스트**: 하나의 질문에 대한 25개 페르소나 응답
2. **전체 질문 테스트**: 11개 질문에 대한 275개 응답
3. **에러 복구 테스트**: 일부 실패 시 재시도 및 복구

### **성능 테스트**
1. **배치 크기별 성능**: 10개, 25개, 50개 단위 처리 속도
2. **동시 처리 테스트**: 여러 Batch 작업 동시 실행
3. **메모리 사용량 모니터링**: 처리 과정에서의 메모리 사용 패턴

### **품질 테스트**
1. **응답 다양성**: 페르소나별 응답의 차별화 정도
2. **일관성 검증**: 동일 조건에서의 응답 일관성
3. **TCI 특성 반영**: 기질과 성격이 응답에 제대로 반영되는지 확인

## 사용 방법

### **1. 기본 테스트 실행**
```bash
# conda 환경 활성화
conda activate batchpro

# Jupyter 노트북 실행
cd batchtest
jupyter notebook "create_patients_answer (1).ipynb"
```

### **2. Batch API 테스트**
```bash
# 메인 API에서 Batch 테스트
cd ../myapi
python test_batch_processing.py
```

### **3. 성능 비교 테스트**
```bash
# 개별 vs Batch 처리 성능 비교
python performance_comparison.py
```

## 테스트 데이터 구조

### **JSONL 형식 예시**
```json
{"model": "gpt-4-turbo-preview", "input": "질문: 어디가 불편해서 방문하게 되었나요?\n페르소나: 고립되고 겁이 많은, 미성숙한"}
{"model": "gpt-4-turbo-preview", "input": "질문: 어디가 불편해서 방문하게 되었나요?\n페르소나: 폭발적인, 비논리적인"}
```

### **테스트 케이스**
- **기본 질문**: 11개 표준화된 심리 상담 질문
- **페르소나 조합**: 25개 선택된 TCI 조합
- **입력 변형**: 다양한 환자 정보 및 증상

## 성능 지표

### **처리 시간**
- **개별 처리**: 10개 응답당 ~30초
- **Batch 처리**: 10개 응답당 ~8초
- **전체 처리**: 275개 응답당 ~27-28분

### **비용 효율성**
- **API 호출 감소**: 개별 처리 대비 90% 이상 감소
- **처리 속도 향상**: 3-5배 속도 향상
- **동시성 향상**: 여러 요청을 동시에 처리

## 문제 해결

### **일반적인 문제**
- **Rate Limit**: API 호출 간격 조정
- **메모리 부족**: 배치 크기 조정
- **네트워크 오류**: 재시도 로직 구현

### **Batch API 특화 문제**
- **작업 상태 확인**: `check_batch_status` 활용
- **결과 다운로드**: `download_batch_results` 활용
- **에러 로그**: 상세한 에러 정보 확인

## 모니터링 및 로깅

### **성능 모니터링**
- **처리 진행률**: 실시간 진행 상황 표시
- **에러율**: 실패한 요청 비율 추적
- **응답 시간**: 각 단계별 소요 시간 측정

### **로그 분석**
- **성공/실패 패턴**: 에러 발생 패턴 분석
- **성능 트렌드**: 시간에 따른 성능 변화 추적
- **리소스 사용량**: CPU, 메모리, 네트워크 사용량

## 향후 개선 계획

### **단기 개선**
- **에러 복구 강화**: 자동 재시도 및 복구 로직
- **모니터링 개선**: 실시간 대시보드 구축
- **테스트 자동화**: CI/CD 파이프라인 구축

### **장기 개선**
- **AI 모델 최적화**: 더 효율적인 모델 선택
- **분산 처리**: 여러 서버를 활용한 병렬 처리
- **캐싱 시스템**: 자주 사용되는 응답 캐싱

## 라이선스
이 프로젝트는 MIT 라이선스 하에 배포됩니다.
